{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547ac305-dad0-45b3-9d73-ed724242fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byte_order: little\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import QmdlLogsHelper\n",
    "import numpy as np\n",
    "import sys; print(f\"byte_order: {sys.byteorder}\")\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22df7062-b3e3-4be1-9997-e1425091043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"/disk/sean/5glogs\"\n",
    "path_logs = \"sa_log/nr-airondiag_Thu_Apr_18_17-44-36_2024/diag_Thu_Apr_18_17-44-36_2024\"\n",
    "path_file = \"qmdl_1.qmdl\"\n",
    "qmdl_logs_path = Path(path_project) / Path(path_logs) / Path(path_file)\n",
    "logs_helper = QmdlLogsHelper(qmdl_logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ad2fad-a286-4ee9-99d6-cf46cd05cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287764, 5480) <class 'numpy.ndarray'>\n",
      "[[0.07450981 0.07058824 0.41568628 ... 0.         0.         0.        ]\n",
      " [0.2627451  0.15686275 0.         ... 0.         0.         0.        ]\n",
      " [0.6156863  0.27058825 0.7529412  ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(logs_helper.get_logs_array().shape, type(logs_helper.get_logs_array()))\n",
    "print(logs_helper.get_logs_array()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3636fa7a-9c86-40d3-870f-4075850e1b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 [266669 269336 270887 272919 280668] (287764,)\n"
     ]
    }
   ],
   "source": [
    "labels_array = logs_helper.get_detach_request_labels_array()\n",
    "# labels_array = labels_array[:50000]\n",
    "print(np.sum(labels_array), np.where(labels_array == 1)[0][-5:], labels_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509a4a0b-e0cb-40aa-be66-d4102941ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287664 [[  0 100   0]\n",
      " [  1 101   0]\n",
      " [  2 102   0]] <class 'numpy.uint32'>\n"
     ]
    }
   ],
   "source": [
    "logs_array = logs_helper.get_logs_array()\n",
    "LOGS_CHUNK_SIZE = 100\n",
    "data = [np.array([i, i+LOGS_CHUNK_SIZE, labels_array[i:i+LOGS_CHUNK_SIZE].sum(dtype=np.uint32)], dtype=np.uint32) for i in range(len(logs_array)-LOGS_CHUNK_SIZE)]\n",
    "data = np.vstack(data)\n",
    "print(len(data), data[:3], type(data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d71b388-2b61-4d22-9eb3-e08472217189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(logs_array[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92cd8560-e4ce-4624-876d-66f4a6c296da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287664 [[  0 100   0]\n",
      " [  1 101   0]\n",
      " [  2 102   0]] <class 'numpy.uint32'>\n"
     ]
    }
   ],
   "source": [
    "data = logs_helper.get_dataset(chunk_size=100)\n",
    "print(len(data), data[:3], type(data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f38569b3-104b-4eef-849d-aaa32674e855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287664 == 287664 ( = 262690 + 24974 )\n"
     ]
    }
   ],
   "source": [
    "data_label0 = data[np.where(data[:,2] == 0)[0]]\n",
    "data_label1 = data[np.where(data[:,2] > 0)[0]]\n",
    "# data_label2 = data[np.where(data[:,2]==2)[0]]\n",
    "# data_label3 = data[np.where(data[:,2]==3)[0]]\n",
    "# assert len(data) == sum([len(data[np.where(data[:,2]==i)[0]]) for i in range(4)])\n",
    "assert len(data) == len(data_label0) + len(data_label1)\n",
    "print(f\"{len(data)} == {len(data_label0) + len(data_label1)} ( = {len(data_label0)} + {len(data_label1)} )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd17724-446c-4d70-93c3-a8a64207012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26269"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label0_0 = data_label0[np.mod(data_label0[:,0], 10) == 0]\n",
    "len(data_label0_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a9c366-4284-4194-b155-6b963aa77b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=0, data_count=0\n",
      "label=1, data_count=23952\n",
      "label=2, data_count=918\n",
      "label=3, data_count=104\n"
     ]
    }
   ],
   "source": [
    "assert len(data_label1[np.where(data_label1[:,2]>0)[0]]) == sum([len(data_label1[np.where(data_label1[:,2]==i)[0]]) for i in range(1, 4)])\n",
    "for i in range(4):\n",
    "    print(f\"label={i}, data_count={len(data_label1[np.where(data_label1[:,2]==i)[0]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a24058fe-1346-44e5-bb2e-d11007cd7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24974\n",
      "label=0, data_count=0\n",
      "label=1, data_count=24974\n",
      "label=2, data_count=0\n",
      "label=3, data_count=0\n"
     ]
    }
   ],
   "source": [
    "data_label1_1 = data[np.where(data[:,2] > 0)[0]]; print(len(data_label1_1))\n",
    "data_label1_1[:, 2] = 1\n",
    "for i in range(4):\n",
    "    print(f\"label={i}, data_count={len(data_label1_1[np.where(data_label1_1[:,2]==i)[0]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215d675f-017e-439a-bee8-62160a7ef201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46118 5125 22476 2498\n"
     ]
    }
   ],
   "source": [
    "data_balanced = np.vstack([data_label0_0, data_label1_1])\n",
    "x = data_balanced[:, 0:2]\n",
    "y = data_balanced[:, 2]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42, stratify=y)\n",
    "print(len(x_train), len(x_test), sum(y_train), sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8db7d59-d257-44e3-b248-21f9b32ed1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180582, 180682], dtype=uint32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5da7aca-9790-4857-bc0f-c3291171381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75, 43, 64,  8, 99])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "rng.choice(100, size=5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6db67f76-2366-4a82-a04e-e0cc12670c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "LOG_LENGTH = 5480 # len(max(logs_list, key=len)) == 5480\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\tdef __init__(self, d_model=80, n_signals=2, dropout=0.1):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# Project the dimension of features from that of input into d_model.\n",
    "\t\tself.prenet = nn.Linear(LOG_LENGTH, d_model)\n",
    "\t\t# TODO:\n",
    "\t\t#   Change Transformer to Conformer.\n",
    "\t\t#   https://arxiv.org/abs/2005.08100\n",
    "\t\tself.encoder_layer = nn.TransformerEncoderLayer(\n",
    "\t\t\td_model=d_model, dim_feedforward=256, nhead=2\n",
    "\t\t)\n",
    "\t\t# self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
    "\n",
    "\t\t# Project the the dimension of features from d_model into speaker nums.\n",
    "\t\tself.pred_layer = nn.Sequential(\n",
    "\t\t\tnn.Linear(d_model, d_model),\n",
    "\t\t\tnn.Sigmoid(),\n",
    "\t\t\tnn.Linear(d_model, n_signals),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, logs):\n",
    "\t\t\"\"\"\n",
    "\t\targs:\n",
    "            logs: (batch_size, CHUNK_SIZE, LOG_LENGTH)\n",
    "\t\treturn:\n",
    "\t\t\tout: (batch size, n_signals)\n",
    "\t\t\"\"\"\n",
    "\t\t# out: (batch size, length, d_model)\n",
    "\t\tout = self.prenet(logs)\n",
    "\t\t# out: (length, batch size, d_model)\n",
    "\t\tout = out.permute(1, 0, 2)\n",
    "\t\t# The encoder layer expect features in the shape of (length, batch size, d_model).\n",
    "\t\tout = self.encoder_layer(out)\n",
    "\t\t# out: (batch size, length, d_model)\n",
    "\t\tout = out.transpose(0, 1)\n",
    "\t\t# mean pooling\n",
    "\t\tstats = out.mean(dim=1)\n",
    "\n",
    "\t\t# out: (batch, n_spks)\n",
    "\t\tout = self.pred_layer(stats)\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "021480a0-8a2f-47ae-85a3-85207dc60eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import math\n",
    "import torch\n",
    "\n",
    "def get_cosine_schedule_with_warmup(\n",
    "\toptimizer: Optimizer,\n",
    "\tnum_warmup_steps: int,\n",
    "\tnum_training_steps: int,\n",
    "\tnum_cycles: float = 0.5,\n",
    "\tlast_epoch: int = -1,\n",
    "):\n",
    "\t\"\"\"\n",
    "\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n",
    "\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
    "\tinitial lr set in the optimizer.\n",
    "\n",
    "\tArgs:\n",
    "\t\toptimizer (:class:`~torch.optim.Optimizer`):\n",
    "\t\tThe optimizer for which to schedule the learning rate.\n",
    "\t\tnum_warmup_steps (:obj:`int`):\n",
    "\t\tThe number of steps for the warmup phase.\n",
    "\t\tnum_training_steps (:obj:`int`):\n",
    "\t\tThe total number of training steps.\n",
    "\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
    "\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
    "\t\tfollowing a half-cosine).\n",
    "\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n",
    "\t\tThe index of the last epoch when resuming training.\n",
    "\n",
    "\tReturn:\n",
    "\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "\t\"\"\"\n",
    "\tdef lr_lambda(current_step):\n",
    "\t\t# Warmup\n",
    "\t\tif current_step < num_warmup_steps:\n",
    "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
    "\t\t# decadence\n",
    "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
    "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
    "\t\t)\n",
    "\t\treturn max(\n",
    "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
    "\t\t)\n",
    "\n",
    "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2dcccc5-739e-4bd0-8d21-5546d53f519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def model_fn(batch, model, criterion, device):\n",
    "\t\"\"\"Forward a batch through the model.\"\"\"\n",
    "\n",
    "\tlogs, labels = batch\n",
    "\tlogs = logs.to(device)\n",
    "\tlabels = labels.to(device)\n",
    "\n",
    "\touts = model(logs)\n",
    "\n",
    "\tloss = criterion(outs, labels)\n",
    "\n",
    "\t# Get the speaker id with highest probability.\n",
    "\tpreds = outs.argmax(1)\n",
    "\t# Compute accuracy.\n",
    "\taccuracy = torch.mean((preds == labels).float())\n",
    "\n",
    "\treturn loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db5040e-b2f4-452f-af9e-89cdd995aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def valid(dataloader, model, criterion, device): \n",
    "\t\"\"\"Validate on validation set.\"\"\"\n",
    "\n",
    "\tmodel.eval()\n",
    "\trunning_loss = 0.0\n",
    "\trunning_accuracy = 0.0\n",
    "\tpbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n",
    "\n",
    "\tfor i, batch in enumerate(dataloader):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tloss, accuracy = model_fn(batch, model, criterion, device)\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\t\t\trunning_accuracy += accuracy.item()\n",
    "\n",
    "\t\tpbar.update(dataloader.batch_size)\n",
    "\t\tpbar.set_postfix(\n",
    "\t\t\tloss=f\"{running_loss / (i+1):.2f}\",\n",
    "\t\t\taccuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
    "\t\t)\n",
    "\n",
    "\tpbar.close()\n",
    "\tmodel.train()\n",
    "\n",
    "\treturn running_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f70ed2c-ec53-48cd-b120-7745f6acabca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n"
     ]
    }
   ],
   "source": [
    "from data import QmdlDataset\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def parse_args():\n",
    "\t\"\"\"arguments\"\"\"\n",
    "\tconfig = {\n",
    "\t\t\"data_dir\": \"./Dataset\",\n",
    "\t\t\"save_path\": \"model.ckpt\",\n",
    "\t\t\"batch_size\": 32,\n",
    "\t\t\"n_workers\": 8,\n",
    "\t\t\"valid_steps\": 2000,\n",
    "\t\t\"warmup_steps\": 1000,\n",
    "\t\t\"save_steps\": 10000,\n",
    "\t\t\"total_steps\": 70000,\n",
    "\t}\n",
    "\treturn config\n",
    "\n",
    "def main(\n",
    "\tdata_dir,\n",
    "\tsave_path,\n",
    "\tbatch_size,\n",
    "\tn_workers,\n",
    "\tvalid_steps,\n",
    "\twarmup_steps,\n",
    "\ttotal_steps,\n",
    "\tsave_steps,\n",
    "):\n",
    "    \"\"\"Main function.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "    ds_train = QmdlDataset(qmdl_logs_path, split='train')\n",
    "    ds_test = QmdlDataset(qmdl_logs_path, split='test')\n",
    "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=False)\n",
    "    dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
    "    test_features, test_labels = next(iter(dl_test))\n",
    "    print(test_features.shape, test_labels.shape, test_labels)\n",
    "\t# train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
    "\t# train_iterator = iter(train_loader)\n",
    "\t# print(f\"[Info]: Finish loading data!\",flush = True)\n",
    "\n",
    "\t# model = Classifier(n_spks=speaker_num).to(device)\n",
    "\t# criterion = nn.CrossEntropyLoss()\n",
    "\t# optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "\t# scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "\t# print(f\"[Info]: Finish creating model!\",flush = True)\n",
    "\n",
    "\t# best_accuracy = -1.0\n",
    "\t# best_state_dict = None\n",
    "\n",
    "\t# pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "\t# for step in range(total_steps):\n",
    "\t# \t# Get data\n",
    "\t# \ttry:\n",
    "\t# \t\tbatch = next(train_iterator)\n",
    "\t# \texcept StopIteration:\n",
    "\t# \t\ttrain_iterator = iter(train_loader)\n",
    "\t# \t\tbatch = next(train_iterator)\n",
    "\n",
    "\t# \tloss, accuracy = model_fn(batch, model, criterion, device)\n",
    "\t# \tbatch_loss = loss.item()\n",
    "\t# \tbatch_accuracy = accuracy.item()\n",
    "\n",
    "\t# \t# Updata model\n",
    "\t# \tloss.backward()\n",
    "\t# \toptimizer.step()\n",
    "\t# \tscheduler.step()\n",
    "\t# \toptimizer.zero_grad()\n",
    "\n",
    "\t# \t# Log\n",
    "\t# \tpbar.update()\n",
    "\t# \tpbar.set_postfix(\n",
    "\t# \t\tloss=f\"{batch_loss:.2f}\",\n",
    "\t# \t\taccuracy=f\"{batch_accuracy:.2f}\",\n",
    "\t# \t\tstep=step + 1,\n",
    "\t# \t)\n",
    "\n",
    "\t# \t# Do validation\n",
    "\t# \tif (step + 1) % valid_steps == 0:\n",
    "\t# \t\tpbar.close()\n",
    "\n",
    "\t# \t\tvalid_accuracy = valid(valid_loader, model, criterion, device)\n",
    "\n",
    "\t# \t\t# keep the best model\n",
    "\t# \t\tif valid_accuracy > best_accuracy:\n",
    "\t# \t\t\tbest_accuracy = valid_accuracy\n",
    "\t# \t\t\tbest_state_dict = model.state_dict()\n",
    "\n",
    "\t# \t\tpbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "\t# \t# Save the best model so far.\n",
    "\t# \tif (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
    "\t# \t\ttorch.save(best_state_dict, save_path)\n",
    "\t# \t\tpbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
    "\n",
    "\t# pbar.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain(**parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad04c284-8497-42bd-8740-905408ca32df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n",
      "torch.float32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[Info]: Use {device} now!\")\n",
    "outs = torch.tensor([[-0.4479,  0.0522],\n",
    "        [-0.4415,  0.0304],\n",
    "        [-0.4452,  0.0278],\n",
    "        [-0.4706,  0.0399],\n",
    "        [-0.4554,  0.0350],\n",
    "        [-0.4750,  0.0309],\n",
    "        [-0.4432,  0.0390],\n",
    "        [-0.4480,  0.0473],\n",
    "        [-0.4636,  0.0588],\n",
    "        [-0.4737,  0.0599],\n",
    "        [-0.4384,  0.0442],\n",
    "        [-0.4327,  0.0208],\n",
    "        [-0.4271,  0.0200],\n",
    "        [-0.4546,  0.0381],\n",
    "        [-0.3925, -0.0133],\n",
    "        [-0.3263, -0.0047],\n",
    "        [-0.4414,  0.0381],\n",
    "        [-0.4638,  0.0415],\n",
    "        [-0.4415,  0.0392],\n",
    "        [-0.4728,  0.0528],\n",
    "        [-0.4769,  0.0532],\n",
    "        [-0.4473,  0.0420],\n",
    "        [-0.4592,  0.0274],\n",
    "        [-0.4665,  0.0579],\n",
    "        [-0.4809,  0.0543],\n",
    "        [-0.4532,  0.0338],\n",
    "        [-0.4379,  0.0169],\n",
    "        [-0.4772,  0.0332],\n",
    "        [-0.4451,  0.0540],\n",
    "        [-0.3530,  0.0109],\n",
    "        [-0.4492,  0.0408],\n",
    "        [-0.4688,  0.0467]], dtype=torch.float)\n",
    "targets = torch.tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
    "        0, 1, 1, 1, 1, 0, 1, 0], dtype=torch.long)\n",
    "outs.to(device)\n",
    "targets.to(device)\n",
    "print(outs.dtype, targets.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c99ecfa-cc92-4a3b-831d-7e598a5673f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6426)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion(outs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0690a76-a59a-4936-b139-738aff9f0519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b910e1-58ae-4fbb-a056-10258769ab0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35395cd2-1db4-4f5b-8d77-3bc859935db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x03\\xff'\n",
      "b'\\xff\\x03'\n",
      "b'\\xff\\x03'\n"
     ]
    }
   ],
   "source": [
    "print(struct.pack('>h', 1023)) # b'\\x03\\xff'\n",
    "print(struct.pack('=h', 1023)) # native, b'\\xff\\x03'\n",
    "print(struct.pack('<h', 1023)) # little, b'\\xff\\x03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5645f6-cf0c-4e20-9e98-e38a1bc69f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct.calcsize('<c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ffc6e8-125d-4d4f-a4ba-d5489552fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4627,) <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "a = struct.unpack('<h', data[:2])\n",
    "print(a, type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac437a9-3cba-4de9-a7a5-efce73f9bf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x12\\x13'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct.pack('>h', struct.unpack('<h', data[:2])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697a1708-c0c1-46a9-9b18-ad17757eaf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24737113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229accef-d61d-4c1b-a8de-1b7daf9492c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 18\n",
      "106 125\n",
      "94 67\n",
      "40 126\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(bdata[:8]), 2):\n",
    "    print(bdata[i], bdata[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fc95dce-2f51-488f-9497-01d1e7a674b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x13\\x12j}^C(~' b'\\x13j^('\n"
     ]
    }
   ],
   "source": [
    "print(bdata[:8], bdata[:8:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "000473a9-41c4-4675-ada3-1334cb7e5999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 18\n",
      "106 125\n",
      "94 67\n",
      "40 126\n"
     ]
    }
   ],
   "source": [
    "bd2 = []\n",
    "for elem1, elem2 in zip(bdata[0:8:2], bdata[1:8:2]):\n",
    "    print(elem1, elem2)\n",
    "    bd2.extend([elem2, elem1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab892e5f-cf9a-4bac-a8b2-9bcbcde7c4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 19, 125, 106, 67, 94, 126, 40] b'\\x12\\x13}jC^~(' <class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "print(bd2, bytes(bd2), type(bytes(bd2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb2c6377-b967-4646-a7c0-2b84012fb0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.finxter.com/python-read-binary-file/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1796cd33-7ba7-41b4-97ab-e7d303d1ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd3 = []\n",
    "for elem1, elem2 in zip(bdata[::2], bdata[1::2]):\n",
    "    bd3.extend([elem2, elem1])\n",
    "if len(bd3) < len(bdata):\n",
    "    for elem2 in bdata[-1:]:\n",
    "        bd3.append(elem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52b0966a-b67b-4239-bc05-4842a6be439b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24737113, 24737113)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bd3), len(bdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92806876-8b92-4dc7-a65a-f63b8c08befd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([131, 97, 126], b'a\\x83~')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd3[-3:], bdata[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39a3fd03-ffae-4644-9840-37456be6c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qmdl_1_swapped.qmdl\", \"wb\") as f:\n",
    "    f.write(bytes(bd3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d49d08a6-0140-46b3-a067-197cc6a91a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x12\\x13}jC^~(E\\x9d'\n",
      "b'\\x12\\x13}jC^~(E\\x9d' <class 'bytes'>\n",
      "12137d6a435e7e28459d\n"
     ]
    }
   ],
   "source": [
    "with open(\"qmdl_1_swapped.qmdl\", \"rb\") as f:\n",
    "    bdata = f.read() # \n",
    "    data = bdata[:10]\n",
    "    print(f\"{bdata[:10]}\")\n",
    "    print(f\"{data}\", type(data))\n",
    "    print(f\"{bdata[:10].hex()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
